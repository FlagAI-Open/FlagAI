![FlagAI](logo.png)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6052/badge)](https://bestpractices.coreinfrastructure.org/projects/6052)
[![Python application](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml/badge.svg)](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml)
![GitHub release (release name instead of tag name)](https://img.shields.io/github/v/release/FlagAI-Open/FlagAI?include_prereleases&style=social)
[English](README.md)

--------------------------------------------------------------------------------

é£æ™ºæ˜¯ä¸€ä¸ªå¿«é€Ÿã€æ˜“äºä½¿ç”¨å’Œå¯æ‰©å±•çš„å¤§æ¨¡å‹å·¥å…·åŒ…ã€‚ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ”¯æŒåœ¨å¤šæ¨¡æ€çš„å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šè®­ç»ƒã€å¾®è°ƒå’Œéƒ¨ç½²å¤§è§„æ¨¡æ¨¡å‹ã€‚
<br><br>

* ç°åœ¨æ”¯æŒå¤šæ¨¡æ€æ¨¡å‹[**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP)å’Œæ–‡ç”Ÿå›¾æ¨¡å‹[**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion) [![Huggingface space](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Space-cyan.svg)](https://huggingface.co/spaces/BAAI/bilingual_stable_diffusion).ç°åœ¨å®ƒæ”¯æŒæœ€é«˜ç™¾äº¿å‚æ•°çš„**æ‚Ÿé“GLM**(è¯¦è§[GLMä»‹ç»](/doc_zh/GLM.md))ã€‚å®ƒåŒæ—¶ä¹Ÿæ”¯æŒ[**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP)ã€**OPT**ã€**BERT**ã€**RoBERTa**ã€**GPT2**ã€**T5**ã€**ALM**æ¨¡å‹å’Œ Huggingface Transformers çš„æ¨¡å‹ã€‚

* å®ƒæä¾› API ä»¥å¿«é€Ÿä¸‹è½½å¹¶åœ¨ç»™å®šï¼ˆä¸­/è‹±æ–‡ï¼‰æ–‡æœ¬ä¸Šä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ï¼Œåœ¨ä»[SuperGLUE](https://super.gluebenchmark.com/)å’Œ[CLUE](https://github.com/CLUEbenchmark/CLUE) benchmarksæ”¶é›†çš„å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šå¯¹å®ƒä»¬è¿›è¡Œå¾®è°ƒï¼Œç„¶ååœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­å¿ƒä¸ç¤¾åŒºå…±äº«å®ƒä»¬ã€‚ å®ƒè¿˜æä¾›äº†æç¤ºå­¦ä¹ ï¼ˆ[prompt-learning](https://github.com/FlagAI-Open/FlagAI/blob/master/docs/TUTORIAL_7_PROMPT_LEARNING.md)ï¼‰çš„å·¥å…·åŒ…ï¼Œç”¨äºå°‘æ ·æœ¬å­¦ä¹ (few-shot learning)ä»»åŠ¡ã€‚

* è¿™äº›æ¨¡å‹å¯ä»¥åº”ç”¨äºæ–‡æœ¬ï¼Œç”¨äºæ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æå–ã€é—®ç­”ã€æ‘˜è¦ã€æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯ä¸­æ–‡ã€‚

* é£æ™ºç”±ä¸‰ä¸ªæœ€æµè¡Œçš„æ•°æ®/æ¨¡å‹å¹¶è¡Œåº“ï¼ˆ[PyTorch](https://pytorch.org/)/[Deepspeed](https://www.deepspeed.ai/)/[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)ï¼‰æä¾›æ”¯æŒï¼Œå®ƒä»¬ä¹‹é—´å®ç°äº†æ— ç¼é›†æˆã€‚ ä½ å¯ä»¥ç”¨ä¸åˆ°åè¡Œä»£ç æ¥å¹¶è¡Œä½ çš„è®­ç»ƒ/æµ‹è¯•è¿‡ç¨‹ã€‚


æœ¬é¡¹ç›®çš„éƒ¨åˆ†ä»£ç åŸºäº[GLM](https://github.com/THUDM/GLM)ï¼Œ[Transformers](https://github.com/huggingface/transformers)ï¼Œ[timm](https://github.com/rwightman/pytorch-image-models) å’Œ [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM).

## åŠ¨æ€
- [28 Nov 2022] å‘å¸ƒv1.5.0ç‰ˆæœ¬, æ”¯æŒ1.1Bå‚æ•°çš„ [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP) ä»¥åŠ[ALM: åŸºäºGLMçš„é˜¿æ‹‰ä¼¯è¯­å¤§æ¨¡å‹], ç¤ºä¾‹è§[**ALM**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/ALM)
- [10 Nov 2022] å‘å¸ƒv1.4.0ç‰ˆæœ¬, æ”¯æŒ[AltCLIP: æ›´æ”¹CLIPä¸­çš„è¯­è¨€ç¼–ç å™¨ä»¥æ‰©å±•è¯­è¨€åŠŸèƒ½](https://arxiv.org/abs/2211.06679v1), ç¤ºä¾‹è§[**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP)ä»¥åŠ[**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion)
- [29 Aug 2022] æ”¯æŒv1.3.0ç‰ˆæœ¬, å¢åŠ CLIPæ¨¡å—ä»¥åŠé‡æ–°è®¾è®¡äº†tokenizerçš„API: [#81](https://github.com/FlagAI-Open/FlagAI/pull/81)
- [21 Jul 2022] æ”¯æŒv1.2.0ç‰ˆæœ¬, æ”¯æŒViTç³»åˆ—æ¨¡å‹: [#71](https://github.com/FlagAI-Open/FlagAI/pull/71)
- [29 Jun 2022] æ”¯æŒv1.1.0ç‰ˆæœ¬, æ”¯æŒOPTçš„åŠ è½½ï¼Œå¾®è°ƒå’Œæ¨ç†[#63](https://github.com/FlagAI-Open/FlagAI/pull/63)
- [17 May 2022] åšå‡ºäº†æˆ‘ä»¬çš„ç¬¬ä¸€ä»½è´¡çŒ®[#1](https://github.com/FlagAI-Open/FlagAI/pull/1)

--------------------------------------------------------------------------------
<!-- toc -->

- [å®‰è£…](#å®‰è£…)
- [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
    - [åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨](#åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨)
    - [ä½¿ç”¨é¢„æµ‹å™¨](#ä½¿ç”¨é¢„æµ‹å™¨)
    - [æ–‡ç”Ÿå›¾ä»»åŠ¡ç¤ºä¾‹](/examples/AltDiffusion/README.md)
- [é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠæ ·ä¾‹](#é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠæ ·ä¾‹)
- [æ•™ç¨‹](#æ•™ç¨‹)
- [è´¡çŒ®ä»£ç ](#è´¡çŒ®ä»£ç )
- [è”ç³»æˆ‘ä»¬](#è”ç³»æˆ‘ä»¬)
- [è®¸å¯è¯](#è®¸å¯è¯)

<!-- tocstop -->
# å®‰è£…
* PyTorch ç‰ˆæœ¬ >= 1.8.0
* Python ç‰ˆæœ¬ >= 3.8
* ä½¿ç”¨GPUsè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•, ä½ éœ€è¦å®‰è£…CUDA å’Œ NCCL

é€šè¿‡`pip`å®‰è£…:
```shell
pip install -U flagai
```

- [å¯é€‰]ä¸‹è½½æºç å®‰è£…:

```shell
git clone https://github.com/FlagAI-Open/FlagAI.git
python setup.py install
```

- [å¯é€‰] å¼€å¯è®­ç»ƒåŠ é€Ÿéœ€è¦å®‰è£… NVIDIAçš„ [apex](https://github.com/NVIDIA/apex)
```
git clone https://github.com/NVIDIA/apex
cd apex
pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
```
- [å¯é€‰] ä½¿ç”¨ ZeRO ä¼˜åŒ–å™¨ï¼Œéœ€è¦å®‰è£… [DEEPSPEED](https://github.com/microsoft/DeepSpeed)
```
git clone https://github.com/microsoft/DeepSpeed
cd DeepSpeed
DS_BUILD_CPU_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 pip install -e .
ds_report # æ£€æŸ¥deepspeedçš„çŠ¶æ€
```
- [æç¤º] å•èŠ‚ç‚¹dockerç¯å¢ƒä¸‹ï¼Œè¿è¡Œå¤šå¡æ•°æ®å¹¶è¡Œéœ€è¦è®¾ç½®hostã€‚ ä¾‹å¦‚ï¼ŒdockerèŠ‚ç‚¹ root@127.0.0.1ï¼Œå…¶ç«¯å£ 7110ã€‚
```
>>> vim ~/.ssh/config
Host 127.0.0.1
    Hostname 127.0.0.1
    Port 7110
    User root
```
- [æç¤º] å¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œ éœ€è¦ç”Ÿæˆ ssh keys å¹¶æ‹·è´å…¬é’¥åˆ°æ‰€æœ‰èŠ‚ç‚¹ (in `~/.ssh/`)
```
>>> ssh-keygen -t rsa -C "xxx@xxx.com"
```


# å¿«é€Ÿä¸Šæ‰‹
æˆ‘ä»¬æä¾›äº†ç²¾é€‰çš„ä¸­è‹±æ–‡é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥åŠç»è¿‡è®­ç»ƒå¯ä»¥æ‰§è¡Œä¸åŒä»»åŠ¡çš„æ¨¡å‹æƒé‡ã€‚ æ‚¨å¯ä»¥é€šè¿‡ `AutoLoader` ç±»åŠ è½½è¿™äº›æ¨¡å‹ä»¥è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹ã€‚æ›´å¤šæ ·ä¾‹è§ `FlagAI/quickstart`ã€‚

## åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
æˆ‘ä»¬æä¾› `AutoLoad` ç±»æ¥å¿«é€ŸåŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œä¾‹å¦‚ï¼š
```python
from flagai.auto_model.auto_loader import AutoLoader
auto_loader = AutoLoader(
      task_name="title-generation",
      model_name="RoBERTa-base-ch"  
)
model = auto_loader.get_model()
tokenizer = auto_loader.get_tokenizer()
```
è¿™ä¸ªä¾‹å­æ˜¯é’ˆå¯¹`title-generation`(æ–‡æœ¬æ‘˜è¦ï¼‰ä»»åŠ¡çš„ï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡ä¿®æ”¹`task_name`æ¥ä¸ºå…¶ä»–ä»»åŠ¡å»ºæ¨¡ã€‚ ç„¶åæ‚¨å¯ä»¥ä½¿ç”¨æ¨¡å‹å’Œæ ‡è®°å™¨è¿›è¡Œå¾®è°ƒæˆ–æµ‹è¯•ã€‚

## ä½¿ç”¨é¢„æµ‹å™¨
æˆ‘ä»¬æä¾› `Predictor` ç±»æ¥é¢„æµ‹ä¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š
```python
from flagai.model.predictor.predictor import Predictor
predictor = Predictor(model, tokenizer)
test_data = [
    "æœ¬æ–‡æ€»ç»“äº†åä¸ªå¯ç©¿æˆ´äº§å“çš„è®¾è®¡åŸåˆ™è€Œè¿™äº›åŸåˆ™åŒæ ·ä¹Ÿæ˜¯ç¬”è€…è®¤ä¸ºæ˜¯è¿™ä¸ªè¡Œä¸šæœ€å¸å¼•äººçš„åœ°æ–¹1ä¸ºäººä»¬è§£å†³é‡å¤æ€§é—®é¢˜2ä»äººå¼€å§‹è€Œä¸æ˜¯ä»æœºå™¨å¼€å§‹3è¦å¼•èµ·æ³¨æ„ä½†ä¸è¦åˆ»æ„4æå‡ç”¨æˆ·èƒ½åŠ›è€Œä¸æ˜¯å–ä»£äºº",
    "2007å¹´ä¹”å¸ƒæ–¯å‘äººä»¬å±•ç¤ºiPhoneå¹¶å®£ç§°å®ƒå°†ä¼šæ”¹å˜ä¸–ç•Œè¿˜æœ‰äººè®¤ä¸ºä»–åœ¨å¤¸å¤§å…¶è¯ç„¶è€Œåœ¨8å¹´åä»¥iPhoneä¸ºä»£è¡¨çš„è§¦å±æ™ºèƒ½æ‰‹æœºå·²ç»å¸­å·å…¨çƒå„ä¸ªè§’è½æœªæ¥æ™ºèƒ½æ‰‹æœºå°†ä¼šæˆä¸ºçœŸæ­£çš„ä¸ªäººç”µè„‘ä¸ºäººç±»å‘å±•åšå‡ºæ›´å¤§çš„è´¡çŒ®",
    "é›…è™å‘å¸ƒ2014å¹´ç¬¬å››å­£åº¦è´¢æŠ¥å¹¶æ¨å‡ºäº†å…ç¨æ–¹å¼å‰¥ç¦»å…¶æŒæœ‰çš„é˜¿é‡Œå·´å·´é›†å›¢15ï¼…è‚¡æƒçš„è®¡åˆ’æ‰“ç®—å°†è¿™ä¸€ä»·å€¼çº¦400äº¿ç¾å…ƒçš„å®è´µæŠ•èµ„åˆ†é…ç»™è‚¡ä¸œæˆªæ­¢å‘ç¨¿å‰é›…è™è‚¡ä»·ä¸Šæ¶¨äº†å¤§çº¦7ï¼…è‡³5145ç¾å…ƒ"
]
for text in test_data:
    print(
        predictor.predict_generate_beamsearch(text,
                                              out_max_length=50,
                                              beam_size=3))
```
è¿™ä¸ªä¾‹å­æ˜¯é’ˆå¯¹ `seq2seq` ä»»åŠ¡çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨`predict_generate_beamsearch`å‡½æ•°å¾—åˆ°`beam-search`ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ”¯æŒ`NER`å’Œ`title generate`ç­‰ä»»åŠ¡çš„é¢„æµ‹ã€‚


## å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ç¤ºä¾‹

```python
from flagai.auto_model.auto_loader import AutoLoader
from flagai.model.predictor.predictor import Predictor

task_name = "ner"
model_name = "RoBERTa-base-ch"
target = ["O", "B-LOC", "I-LOC", "B-ORG", "I-ORG", "B-PER", "I-PER"]
maxlen = 256

auto_loader = AutoLoader(task_name,
                         model_name=model_name,
                         load_pretrain_params=True,
                         class_num=len(target))

model = auto_loader.get_model()
tokenizer = auto_loader.get_tokenizer()

predictor = Predictor(model, tokenizer)

test_data = [
    "6æœˆ15æ—¥ï¼Œæ²³å—çœæ–‡ç‰©è€ƒå¤ç ”ç©¶æ‰€æ›¹æ“é«˜é™µæ–‡ç‰©é˜Ÿå…¬å¼€å‘è¡¨å£°æ˜æ‰¿è®¤ï¼šâ€œä»æ¥æ²¡æœ‰è¯´è¿‡å‡ºåœŸçš„ç å­æ˜¯å¢“ä¸»äººçš„",
    "4æœˆ8æ—¥ï¼ŒåŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šæ€»ç»“è¡¨å½°å¤§ä¼šåœ¨äººæ°‘å¤§ä¼šå ‚éš†é‡ä¸¾è¡Œã€‚ä¹ è¿‘å¹³æ€»ä¹¦è®°å‡ºå¸­å¤§ä¼šå¹¶å‘è¡¨é‡è¦è®²è¯ã€‚åœ¨è®²è¯ä¸­ï¼Œæ€»ä¹¦è®°å……åˆ†è‚¯å®šäº†åŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šå–å¾—çš„ä¼˜å¼‚æˆç»©ï¼Œå…¨é¢å›é¡¾äº†7å¹´ç­¹åŠå¤‡èµ›çš„ä¸å‡¡å†ç¨‹ï¼Œæ·±å…¥æ€»ç»“äº†ç­¹å¤‡ä¸¾åŠåŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šçš„å®è´µç»éªŒï¼Œæ·±åˆ»é˜é‡Šäº†åŒ—äº¬å†¬å¥¥ç²¾ç¥ï¼Œå¯¹è¿ç”¨å¥½å†¬å¥¥é—äº§æ¨åŠ¨é«˜è´¨é‡å‘å±•æå‡ºæ˜ç¡®è¦æ±‚ã€‚",
    "å½“åœ°æ—¶é—´8æ—¥ï¼Œæ¬§ç›Ÿå§”å‘˜ä¼šè¡¨ç¤ºï¼Œæ¬§ç›Ÿå„æˆå‘˜å›½æ”¿åºœç°å·²å†»ç»“å…±è®¡çº¦300äº¿æ¬§å…ƒä¸ä¿„ç½—æ–¯å¯¡å¤´åŠå…¶ä»–è¢«åˆ¶è£çš„ä¿„æ–¹äººå‘˜æœ‰å…³çš„èµ„äº§ã€‚",
    "è¿™ä¸€ç›˜å£çŠ¶æ€ä¸‹è‹±å›½å¿…å‘å…¬å¸äºšæ´²ç›˜äº¤æ˜“æ•°æ®æ˜¾ç¤ºåšæ´›å°¼äºšçƒ­ã€‚è€Œä»æ¬§èµ”æŠ•æ³¨çœ‹ï¼Œä¹Ÿæ˜¯ä¸»é˜Ÿçƒ­ã€‚å·´å‹’è«ä¸¤è¿è´¥ï¼Œ",
]

for t in test_data:
    entities = predictor.predict_ner(t, target, maxlen=maxlen)
    result = {}
    for e in entities:
        if e[2] not in result:
            result[e[2]] = [t[e[0]:e[1] + 1]]
        else:
            result[e[2]].append(t[e[0]:e[1] + 1])
    print(f"result is {result}")
```


## è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ä»»åŠ¡ç¤ºä¾‹

```python
from flagai.auto_model.auto_loader import AutoLoader
from flagai.model.predictor.predictor import Predictor

maxlen = 256

auto_loader = AutoLoader("semantic-matching",
                         model_name="RoBERTa-base-ch",
                         load_pretrain_params=True,
                         class_num=2)
model = auto_loader.get_model()
tokenizer = auto_loader.get_tokenizer()

predictor = Predictor(model, tokenizer)

test_data = [["åæ‚”äº†å—", "ä½ æœ‰æ²¡æœ‰åæ‚”"], ["æ‰“å¼€è‡ªåŠ¨æ¨ªå±", "å¼€å¯ç§»åŠ¨æ•°æ®"],
             ["æˆ‘è§‰å¾—ä½ å¾ˆèªæ˜", "ä½ èªæ˜æˆ‘æ˜¯è¿™ä¹ˆè§‰å¾—"]]

for text_pair in test_data:
    print(predictor.predict_cls_classifier(text_pair))

```

# é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠæ ·ä¾‹
* [AltCLIPå›¾æ–‡åŒ¹é…](/examples/AltCLIP/README.md)
* [AltDiffusionæ–‡ç”Ÿå›¾](/examples/AltDiffusion/README.md)
* [EVA-CLIPè¯„ä¼°](/examples/AltDiffusion/README.md)
* [GLM-large-chç”¨æˆ·å®Œå½¢å¡«ç©ºé—®ç­”](/doc_zh/TUTORIAL_11_GLM_BLANK_FILLING_QA.md)
* [GLM-large-chç”¨äºè¯—æ­Œç”Ÿæˆ](doc_zh/TUTORIAL_13_GLM_EXAMPLE_PEOTRY_GENERATION.md)
* [GLM-large-chç”¨äºæ ‡é¢˜ç”Ÿæˆ](doc_zh/TUTORIAL_12_GLM_EXAMPLE_TITLE_GENERATION.md)
* [å¯¹ huggingface t5-11b æ¨¡å‹çš„æ”¯æŒä»¥åŠåŠ é€Ÿçš„å°æŠ€å·§](doc_zh/TUTORIAL_14_HUGGINGFACE_T5.md)
* [RoBERTa-base-chç”¨äºæ ‡é¢˜ç”Ÿæˆ](doc_zh/TUTORIAL_15_BERT_EXAMPLE_TITLE_GENERATION.md)
* [RoBERTa-base-chç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…](doc_zh/TUTORIAL_16_BERT_EXAMPLE_SEMANTIC_MATCHING.md)
* [RoBERTa-base-chç”¨äºå‘½åå®ä½“è¯†åˆ«](/doc_zh/TUTORIAL_17_BERT_EXAMPLE_NER.md)
* [GPT-2ç”¨äºæ–‡æœ¬ç»­å†™](/doc_zh/TUTORIAL_18_GPT2_WRITING.md)
* [T5ç”¨äºæ ‡é¢˜ç”Ÿæˆ](/doc_zh/TUTORIAL_19_T5_EXAMPLE_TITLE_GENERATION.md)
* [OPTæ¨¡å‹ç¤ºä¾‹](/examples/opt/README.md)

[//]: # (* [ç”¨GLM10bæ¨¡å‹åœ¨TNEWSçŸ­æ–‡æœ¬åˆ†ç±»æ•°æ®é›†ä¸Šå¾®è°ƒ]&#40;doc_zh/TUTORIAL_20_GLM_TNEWS.md&#41;)


æœ¬èŠ‚è§£é‡Šäº†æœ¬é¡¹ç›®ä¸­åŸºç¡€NLPç±»æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå¦‚ä½•åŠ è½½é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ¥æ ‡è®°æ‚¨çš„æ–‡æœ¬ï¼Œå¦‚ä½•ä½¿ç”¨ä¸åŒçš„è¯æˆ–æ–‡æ¡£åµŒå…¥æ¥å¾—åˆ°è¡¨ç¤ºï¼Œä»¥åŠå¦‚ä½•è®­ç»ƒè‡ªå·±çš„è¯­è¨€æ¨¡å‹ã€åºåˆ—æ ‡æ³¨æ¨¡å‹å’Œæ–‡æœ¬åˆ†ç±»æ¨¡å‹ã€‚æ›´å¤šæ ·ä¾‹è§ `./examples`ç›®å½•ã€‚


# æ•™ç¨‹
æˆ‘ä»¬æä¾›äº†ä¸€ç»„æ•™ç¨‹æ¥å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ä½¿ç”¨æœ¬åº“ï¼š
* [Tutorial 1: å¦‚ä½•æ„å»ºå’Œåº”ç”¨åˆ†è¯å™¨](/doc_zh/TUTORIAL_1_TOKENIZER.md)
* [Tutorial 2: æ•°æ®é›†é¢„å¤„ç†æµç¨‹](/doc_zh/TUTORIAL_2_DATASET.md)
* [Tutorial 3: æ¨¡å‹çš„ä¸»è¦åŠŸèƒ½åŠç›¸å…³ç»“æ„](/doc_zh/TUTORIAL_3_MODEL.md)
* [Tutorial 4: ä¸ºæ¨¡å‹å’Œæ•°æ®å¹¶è¡Œè®­ç»ƒå®šåˆ¶è®­ç»ƒå™¨](/doc_zh/TUTORIAL_4_TRAINER.md)
* [Tutorial 5: ä½¿ç”¨ Autoloader ç®€åŒ–æ¨¡å‹å’Œåˆ†è¯å™¨åˆå§‹åŒ–è¿‡ç¨‹](/doc_zh/TUTORIAL_5_INSTRUCTIONS_FOR_AutoLoader.md)
* [Tutorial 6: å°†ç°æˆçš„æ¨ç†ç®—æ³•ä¸ Predictor ç»“åˆä½¿ç”¨](/doc_zh/TUTORIAL_6_INSTRUCTIONS_FOR_PREDICTOR.md)
* [Tutorial 7: ä½¿ç”¨é£æ™ºæç¤ºå­¦ä¹ å·¥å…·åŒ…æ¥æé«˜åœ¨SuperGLUEä»»åŠ¡ä¸Šçš„è¡¨ç°](/doc_zh/TUTORIAL_7_PROMPT_LEARNING.md)
* [Tutorial 8: å¤šæœºè®­ç»ƒæ¨¡å‹æ­å»ºç¯å¢ƒ](/doc_zh/TUTORIAL_8_ENVIRONMENT_SETUP.md)
* [Tutorial 9: ä½¿ç”¨encoder/decoder/encoder-decoderæ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ](/doc_zh/TUTORIAL_9_SEQ2SEQ_METHOD.md)
* [Turorial 10: è½¬åŒ–ä¸€ä¸ªæ¨¡å‹ä¸ºMegatron-LMçš„æ¨¡å‹å¹¶è¡Œç‰ˆæœ¬](/doc_zh/TUTORIAL_10_METATRON.md)



# è´¡çŒ®ä»£ç 
æ„Ÿè°¢æ‚¨å¯¹è´¡çŒ®çš„å…´è¶£ï¼ å‚ä¸çš„æ–¹å¼æœ‰å¾ˆå¤šï¼› ä»æˆ‘ä»¬çš„[è´¡çŒ®è€…æŒ‡å—](CONTRIBUTING.md)å¼€å§‹ï¼Œç„¶åæ£€æŸ¥è¿™äº›[æœªè§£å†³çš„é—®é¢˜](https://github.com/FlagAI-Open/FlagAI/issues)ä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚

# è”ç³»æˆ‘ä»¬
æ¬¢è¿æ‰«ç åŠ å…¥é£æ™ºç”¨æˆ·ç¾¤

<img src="./flagai_wechat.png" width = "200" height = "200"  align=center />


# [è®¸å¯è¯](/LICENSE)
å¤§éƒ¨åˆ†çš„é£æ™ºé¡¹ç›®æ˜¯åŸºäº[Apache 2.0 license](LICENSE), ä½†æ˜¯éƒ¨åˆ†çš„ä»£ç æ˜¯åŸºäºå…¶ä»–çš„åè®®:

* Megatron-LM æ˜¯åŸºäºåè®®[Megatron-LM license](https://github.com/NVIDIA/Megatron-LM/blob/main/LICENSE)
* GLM æ˜¯åŸºäºåè®®[MIT license](https://github.com/THUDM/GLM/blob/main/LICENSE)
